<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/elia/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/next.svg" fetchPriority="high"/><link rel="stylesheet" href="/elia/_next/static/css/c52be57545dbb877.css" data-precedence="next"/><link rel="stylesheet" href="/elia/_next/static/css/8c04984e96826ffb.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/elia/_next/static/js/webpack.6731601f.js"/><script src="/elia/_next/static/js/fd9d1056.0547a1b9.js" async=""></script><script src="/elia/_next/static/js/23.e7b06c4e.js" async=""></script><script src="/elia/_next/static/js/main-app.858a9c1b.js" async=""></script><script src="/elia/_next/static/js/173.4b72caec.js" async=""></script><script src="/elia/_next/static/js/app/page.705d4283.js" async=""></script><title>Create Next App</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/elia/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/elia/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_29aad1"><main class="page_main__GlU4n"><div class="page_description__86bsR"><p>elia - Terminal-based LLM Chat</p></div><div class="page_center__5oHG7"><img alt="Next.js Logo" fetchPriority="high" width="180" height="37" decoding="async" data-nimg="1" class="page_logo__7fc9l" style="color:transparent" src="/next.svg"/></div><div class="page_grid__f5Kdy"><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Overview <span>-&gt;</span></h2><p>elia is an innovative terminal-based application for interacting with large language models (LLMs). Designed to be keyboard-centric, efficient, and enjoyable, elia offers a seamless way to chat with models like ChatGPT, Claude, Llama 3, Phi 3, Mistral, and Gemma. It stores all conversations locally in an SQLite database, providing flexibility and control over your data.</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Key Features <span>-&gt;</span></h2><p>- Keyboard-Focused Interface - Multiple Model Support - Local Storage - Customizable Interactions</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Problem Addressed <span>-&gt;</span></h2><p>Traditional methods of interacting with LLMs can be cumbersome and inefficient, often requiring multiple steps and different platforms. Users need a streamlined, terminal-based solution that offers both flexibility and efficiency without compromising on functionality.</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Solution Offered <span>-&gt;</span></h2><p>elia offers a robust, terminal-based interface that simplifies the process of interacting with various LLMs. By focusing on keyboard-centric commands and local data storage, elia provides a powerful and efficient solution for users who require quick and reliable access to LLMs.</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>How It Works <span>-&gt;</span></h2><p>- Launch and Chat - Inline and Full-Screen Modes - Model Configuration - Local Models</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Customer Success <span>-&gt;</span></h2><p>Users of elia have reported significant improvements in their workflow efficiency and satisfaction. By integrating multiple LLMs into a single, easy-to-use terminal interface, elia has become a favorite tool for developers, researchers, and AI enthusiasts.</p></a><a href="https://vrtnis.github.io/elia" class="page_card__QV0Om" target="_blank" rel="noopener noreferrer"><h2>Call to Action <span>-&gt;</span></h2><p>Experience the future of LLM interactions with elia. Whether you are a developer looking for a streamlined workflow, a researcher needing efficient access to multiple models, or an AI enthusiast wanting to explore new possibilities, elia is the perfect tool for you.</p></a></div></main><script src="/elia/_next/static/js/webpack.6731601f.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/elia/_next/static/media/c9a5bc6a7c948fb0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/elia/_next/static/css/c52be57545dbb877.css\",\"style\"]\n3:HL[\"/elia/_next/static/css/8c04984e96826ffb.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[5751,[],\"\"]\n6:I[8173,[\"173\",\"static/js/173.4b72caec.js\",\"931\",\"static/js/app/page.705d4283.js\"],\"Image\"]\n7:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\na:I[6130,[],\"\"]\nb:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/elia/_next/static/css/c52be57545dbb877.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"scWKuF2j1fVv7ZyccVjpx\",\"assetPrefix\":\"/elia\",\"initialCanonicalUrl\":\"/\",\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",[\"$\",\"main\",null,{\"className\":\"page_main__GlU4n\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page_description__86bsR\",\"children\":[\"$\",\"p\",null,{\"children\":\"elia - Terminal-based LLM Chat\"}]}],[\"$\",\"div\",null,{\"className\":\"page_center__5oHG7\",\"children\":[\"$\",\"$L6\",null,{\"className\":\"page_logo__7fc9l\",\"src\":\"/next.svg\",\"alt\":\"Next.js Logo\",\"width\":180,\"height\":37,\"priority\":true}]}],[\"$\",\"div\",null,{\"className\":\"page_grid__f5Kdy\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Overview \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"elia is an innovative terminal-based application for interacting with large language models (LLMs). Designed to be keyboard-centric, efficient, and enjoyable, elia offers a seamless way to chat with models like ChatGPT, Claude, Llama 3, Phi 3, Mistral, and Gemma. It stores all conversations locally in an SQLite database, providing flexibility and control over your data.\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Key Features \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"- Keyboard-Focused Interface - Multiple Model Support - Local Storage - Customizable Interactions\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Problem Addressed \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"Traditional methods of interacting with LLMs can be cumbersome and inefficient, often requiring multiple steps and different platforms. Users need a streamlined, terminal-based solution that offers both flexibility and efficiency without compromising on functionality.\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Solution Offered \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"elia offers a robust, terminal-based interface that simplifies the process of interacting with various LLMs. By focusing on keyboard-centric commands and local data storage, elia provides a powerful and efficient solution for users who require quick and reliable access to LLMs.\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"How It Works \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"- Launch and Chat - Inline and Full-Screen Modes - Model Configuration - Local Models\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Customer Success \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"Users of elia have reported significant improvements in their workflow efficiency and satisfaction. By integrating multiple LLMs into a single, easy-to-use terminal interface, elia has become a favorite tool for developers, researchers, and AI enthusiasts.\"}]]}],[\"$\",\"a\",null,{\"href\":\"https://vrtnis.github.io/elia\",\"className\":\"page_card__QV0Om\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"h2\",null,{\"children\":[\"Call to Action \",[\"$\",\"span\",null,{\"children\":\"-\u003e\"}]]}],[\"$\",\"p\",null,{\"children\":\"Experience the future of LLM interactions with elia. Whether you are a developer looking for a streamlined workflow, a researcher needing efficient access to multiple models, or an AI enthusiast wanting to explore new possibilities, elia is the perfect tool for you.\"}]]}]]}]]}]],null],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_29aad1\",\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/elia/_next/static/css/8c04984e96826ffb.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L9\"],\"globalErrorComponent\":\"$a\",\"missingSlots\":\"$Wb\"}]]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Create Next App\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"4\",{\"rel\":\"icon\",\"href\":\"/elia/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"5\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>