2:I[9275,[],""]
3:I[1343,[],""]
0:["ccpTt3OeJgdv2y7k5T0_z",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","main",null,{"className":"page_main__GlU4n","children":[["$","div",null,{"className":"page_section__61PEw","children":["$","h1",null,{"children":"elia - Terminal-based LLM Chat"}]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Overview"}],["$","p",null,{"children":"elia is an innovative terminal-based application for interacting with large language models (LLMs). Designed to be keyboard-centric, efficient, and enjoyable, elia offers a seamless way to chat with models like ChatGPT, Claude, Llama 3, Phi 3, Mistral, and Gemma. It stores all conversations locally in an SQLite database, providing flexibility and control over your data."}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Key Features"}],["$","ul",null,{"className":"page_list__NOc4w","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Keyboard-Focused Interface:"}]," elia is designed for speed and efficiency, allowing you to interact with LLMs directly from your terminal."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Multiple Model Support:"}]," Chat with a variety of models, including proprietary ones like ChatGPT and Claude, and local models through ollama or LocalAI."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Local Storage:"}]," Conversations are saved in a local SQLite database, ensuring your data is always accessible and secure."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Customizable Interactions:"}]," Configure elia to suit your needs, including setting default models, custom prompts, and syntax highlighting themes for code."]}]]}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Problem Addressed"}],["$","p",null,{"children":"Traditional methods of interacting with LLMs can be cumbersome and inefficient, often requiring multiple steps and different platforms. Users need a streamlined, terminal-based solution that offers both flexibility and efficiency without compromising on functionality."}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Solution Offered"}],["$","p",null,{"children":"elia offers a robust, terminal-based interface that simplifies the process of interacting with various LLMs. By focusing on keyboard-centric commands and local data storage, elia provides a powerful and efficient solution for users who require quick and reliable access to LLMs."}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"How It Works"}],["$","ul",null,{"className":"page_list__NOc4w","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Launch and Chat:"}]," Start elia from your terminal and begin chatting with your chosen model instantly."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Inline and Full-Screen Modes:"}]," Use inline mode for quick queries or full-screen mode for more immersive interactions."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Model Configuration:"}]," Easily switch between different models and configure them according to your needs."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Local Models:"}]," Run local models through ollama or LocalAI, giving you the flexibility to work offline and on your terms."]}]]}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Customer Success"}],["$","p",null,{"children":"Users of elia have reported significant improvements in their workflow efficiency and satisfaction. By integrating multiple LLMs into a single, easy-to-use terminal interface, elia has become a favorite tool for developers, researchers, and AI enthusiasts."}]]}],["$","div",null,{"className":"page_section__61PEw","children":[["$","h2",null,{"children":"Call to Action"}],["$","p",null,{"children":"Experience the future of LLM interactions with elia. Whether you are a developer looking for a streamlined workflow, a researcher needing efficient access to multiple models, or an AI enthusiast wanting to explore new possibilities, elia is the perfect tool for you."}],["$","p",null,{"children":["For more information, visit ",["$","a",null,{"href":"https://vrtnis.github.io/elia","target":"_blank","rel":"noopener noreferrer","className":"page_link__36MaQ","children":"elia"}],"."]}]]}]]}]],null],null]},[["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_29aad1","children":["$","$L2",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":[["$","link","0",{"rel":"stylesheet","href":"/elia/_next/static/css/896fe93d13aa577b.css","precedence":"next","crossOrigin":"$undefined"}]]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/elia/_next/static/css/c52be57545dbb877.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L4"]]]]]
4:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Create Next App"}],["$","meta","3",{"name":"description","content":"Generated by create next app"}],["$","link","4",{"rel":"icon","href":"/elia/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
